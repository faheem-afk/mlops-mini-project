{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da9dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, classification_report, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26392c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fc444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df: pd.DataFrame, test_size: float) -> tuple:\n",
    "# delete tweet id\n",
    "    df.drop(columns=['tweet_id'],inplace=True)\n",
    "\n",
    "    final_df = df[df['sentiment'].isin(['happiness','sadness'])]\n",
    "\n",
    "    final_df['sentiment'].replace({'happiness':1, 'sadness':0},inplace=True)\n",
    "    \n",
    "    train_data, test_data = train_test_split(final_df, test_size=test_size, random_state=42)\n",
    "\n",
    "    data_path = os.path.join('data', 'raw')\n",
    "    \n",
    "    return data_path, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239c05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/dlr59jp10wj5hx57q_rhfy3c0000gn/T/ipykernel_56247/3634658538.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df['sentiment'].replace({'happiness':1, 'sadness':0},inplace=True)\n",
      "/var/folders/xh/dlr59jp10wj5hx57q_rhfy3c0000gn/T/ipykernel_56247/3634658538.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df['sentiment'].replace({'happiness':1, 'sadness':0},inplace=True)\n",
      "/var/folders/xh/dlr59jp10wj5hx57q_rhfy3c0000gn/T/ipykernel_56247/3634658538.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sentiment'].replace({'happiness':1, 'sadness':0},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "_, train_data, test_data = process_data(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a636fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;quot;My problem isn't that I miss you... 'cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>That's it? It's done already? This is one proo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>0</td>\n",
       "      <td>I am so hungry! And there is no food for me to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31288</th>\n",
       "      <td>1</td>\n",
       "      <td>Feet hurt...finally in bed...will not forget t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>0</td>\n",
       "      <td>really ill atm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>1</td>\n",
       "      <td>@chocolatesuze yes yes you should! Especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>0</td>\n",
       "      <td>@kickzfadayz Our boy better get it in tonight!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>1</td>\n",
       "      <td>tafe was actually quite good. for once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "      <td>10 minutes to boarding; 14 hours to home. no w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27810</th>\n",
       "      <td>0</td>\n",
       "      <td>Intel gfx driver situation much better with re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "23531          0  &quot;My problem isn't that I miss you... 'cau...\n",
       "8051           0  That's it? It's done already? This is one proo...\n",
       "11499          0  I am so hungry! And there is no food for me to...\n",
       "31288          1  Feet hurt...finally in bed...will not forget t...\n",
       "18561          0                                     really ill atm\n",
       "...          ...                                                ...\n",
       "21697          1  @chocolatesuze yes yes you should! Especially ...\n",
       "19445          0  @kickzfadayz Our boy better get it in tonight!...\n",
       "20216          1             tafe was actually quite good. for once\n",
       "3258           0  10 minutes to boarding; 14 hours to home. no w...\n",
       "27810          0  Intel gfx driver situation much better with re...\n",
       "\n",
       "[8299 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5b9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:33: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/xh/dlr59jp10wj5hx57q_rhfy3c0000gn/T/ipykernel_56247/1460498924.py:33: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  text = re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    text=[lemmatizer.lemmatize(y) for y in text]\n",
    "\n",
    "    return \" \" .join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    Text=[i for i in str(text).split() if i not in stop_words]\n",
    "    return \" \".join(Text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    text=''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    text=[y.lower() for y in text]\n",
    "\n",
    "    return \" \" .join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    ## Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace('؛',\"\", )\n",
    "\n",
    "    ## remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text =  \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "def removing_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_small_sentences(df):\n",
    "    for i in range(len(df)):\n",
    "        if len(df.text.iloc[i].split()) < 3:\n",
    "            df.text.iloc[i] = np.nan\n",
    "\n",
    "def normalize_text(df):\n",
    "    df.content=df.content.apply(lambda content : lower_case(content))\n",
    "    df.content=df.content.apply(lambda content : remove_stop_words(content))\n",
    "    df.content=df.content.apply(lambda content : removing_numbers(content))\n",
    "    df.content=df.content.apply(lambda content : removing_punctuations(content))\n",
    "    df.content=df.content.apply(lambda content : removing_urls(content))\n",
    "    df.content=df.content.apply(lambda content : lemmatization(content))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ad57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed = normalize_text(train_data)\n",
    "test_data_processed = normalize_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb457e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23531</th>\n",
       "      <td>0</td>\n",
       "      <td>quot my problem miss you cause don t quot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>that s it done already one proof there s nothi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>0</td>\n",
       "      <td>hungry food steal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31288</th>\n",
       "      <td>1</td>\n",
       "      <td>foot hurt finally bed will forget crunch over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18561</th>\n",
       "      <td>0</td>\n",
       "      <td>really ill atm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21697</th>\n",
       "      <td>1</td>\n",
       "      <td>chocolatesuze yes yes should especially wine m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>0</td>\n",
       "      <td>kickzfadayz boy better get tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>1</td>\n",
       "      <td>tafe actually quite good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0</td>\n",
       "      <td>minute boarding hour home window seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27810</th>\n",
       "      <td>0</td>\n",
       "      <td>intel gfx driver situation much better recent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "23531          0          quot my problem miss you cause don t quot\n",
       "8051           0  that s it done already one proof there s nothi...\n",
       "11499          0                                  hungry food steal\n",
       "31288          1  foot hurt finally bed will forget crunch over ...\n",
       "18561          0                                     really ill atm\n",
       "...          ...                                                ...\n",
       "21697          1  chocolatesuze yes yes should especially wine m...\n",
       "19445          0                 kickzfadayz boy better get tonight\n",
       "20216          1                           tafe actually quite good\n",
       "3258           0              minute boarding hour home window seat\n",
       "27810          0  intel gfx driver situation much better recent ...\n",
       "\n",
       "[8299 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e135d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>0</td>\n",
       "      <td>look like rained weekend climbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32287</th>\n",
       "      <td>0</td>\n",
       "      <td>hi everyone miss much muahhhhhhhhhhhhhhhhhhhhh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>0</td>\n",
       "      <td>rode moped mall fun stuff flippin gorgeous out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>0</td>\n",
       "      <td>gutted vodafone wont repair faulty samsung omn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>1</td>\n",
       "      <td>shadowowns aww lt thank youu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38000</th>\n",
       "      <td>1</td>\n",
       "      <td>russellburnham nice one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>0</td>\n",
       "      <td>tired climb bed fall asleep hope weekend fun c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38031</th>\n",
       "      <td>1</td>\n",
       "      <td>jadeyyg http twitpic com wrxq whens little gin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14702</th>\n",
       "      <td>0</td>\n",
       "      <td>leirastorm that s sucky miss on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22007</th>\n",
       "      <td>1</td>\n",
       "      <td>got great expectation tomorrow gonna awesome h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2075 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            content\n",
       "11535          0                  look like rained weekend climbing\n",
       "32287          0  hi everyone miss much muahhhhhhhhhhhhhhhhhhhhh...\n",
       "17534          0  rode moped mall fun stuff flippin gorgeous out...\n",
       "4696           0  gutted vodafone wont repair faulty samsung omn...\n",
       "23706          1                       shadowowns aww lt thank youu\n",
       "...          ...                                                ...\n",
       "38000          1                            russellburnham nice one\n",
       "1540           0  tired climb bed fall asleep hope weekend fun c...\n",
       "38031          1  jadeyyg http twitpic com wrxq whens little gin...\n",
       "14702          0                    leirastorm that s sucky miss on\n",
       "22007          1  got great expectation tomorrow gonna awesome h...\n",
       "\n",
       "[2075 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1ab8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed_df = train_data_processed\n",
    "test_preprocessed_df = test_data_processed\n",
    "\n",
    "X_train = train_preprocessed_df['content'].values\n",
    "y_train = train_preprocessed_df['sentiment'].values\n",
    "\n",
    "X_test = test_preprocessed_df['content'].values\n",
    "y_test = test_preprocessed_df['sentiment'].values\n",
    "\n",
    "        \n",
    "# Apply Bag of Words (CountVectorizer)\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "\n",
    "# # Fit the vectorizer on the training data and transform it\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the same vectorizer\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "train_bow = pd.DataFrame(X_train_bow.toarray())\n",
    "train_bow['label'] = y_train\n",
    "\n",
    "test_bow = pd.DataFrame(X_test_bow.toarray())\n",
    "test_bow['label'] = y_test\n",
    "\n",
    "vectorized_df = pd.concat([train_bow, test_bow], axis=0)\n",
    "\n",
    "X = vectorized_df.iloc[:, :-1]\n",
    "y = vectorized_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f255e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"faheem-afk/mlops-mini-project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"faheem-afk/mlops-mini-project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository faheem-afk/mlops-mini-project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository faheem-afk/mlops-mini-project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Faheem/Desktop/mlops-mini-project/mlops-mini-project/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run indecisive-fly-746 at: https://dagshub.com/faheem-afk/mlops-mini-project.mlflow/#/experiments/1/runs/ba125c98cdde4d0ca83f3ee06918c1e8\n",
      "🧪 View experiment at: https://dagshub.com/faheem-afk/mlops-mini-project.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "import mlflow \n",
    "from mlflow.models.signature import infer_signature\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv('MLFLOW-TRACKING-URI'))\n",
    "\n",
    "dagshub.init(repo_owner='faheem-afk', repo_name=\"mlops-mini-project\", mlflow=True)\n",
    "\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"vectorizer\", 'bag of words')\n",
    "    mlflow.log_param(\"num_features\", 1000)\n",
    "    mlflow.log_param(\"test_size\", 0.2)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    mlflow.log_param(\"model\", \"logistic Regression\")\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy_ = accuracy_score(y_test, y_pred)\n",
    "    recall_ = recall_score(y_test, y_pred)\n",
    "    precision_ = precision_score(y_test, y_pred)\n",
    "    f1_score_ = f1_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy_)\n",
    "    mlflow.log_metric(\"recall\", recall_)\n",
    "    mlflow.log_metric(\"precision\", precision_)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score_)\n",
    "    \n",
    "    input_example = X_train.iloc[:5, : ]\n",
    "    \n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    mlflow.sklearn.log_model(model, \"LogisticRegression\", signature=signature, input_example=input_example)\n",
    "    \n",
    "    notebook_path = \"experiment_baseline_model.ipynb\"\n",
    "    # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "    \n",
    "    mlflow.log_artifact(notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8f1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445caaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-mini-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
